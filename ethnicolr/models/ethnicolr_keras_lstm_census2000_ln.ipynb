{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 14:48:18.429550: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-20 14:48:18.429597: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n",
      "2.5.2\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>prop100k</th>\n",
       "      <th>cum_prop100k</th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pctaian</th>\n",
       "      <th>pct2prace</th>\n",
       "      <th>pcthispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH</td>\n",
       "      <td>1</td>\n",
       "      <td>2376206</td>\n",
       "      <td>880.85</td>\n",
       "      <td>880.85</td>\n",
       "      <td>73.35</td>\n",
       "      <td>22.22</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>2</td>\n",
       "      <td>1857160</td>\n",
       "      <td>688.44</td>\n",
       "      <td>1569.30</td>\n",
       "      <td>61.55</td>\n",
       "      <td>33.80</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.82</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3</td>\n",
       "      <td>1534042</td>\n",
       "      <td>568.66</td>\n",
       "      <td>2137.96</td>\n",
       "      <td>48.52</td>\n",
       "      <td>46.72</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BROWN</td>\n",
       "      <td>4</td>\n",
       "      <td>1380145</td>\n",
       "      <td>511.62</td>\n",
       "      <td>2649.58</td>\n",
       "      <td>60.71</td>\n",
       "      <td>34.54</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JONES</td>\n",
       "      <td>5</td>\n",
       "      <td>1362755</td>\n",
       "      <td>505.17</td>\n",
       "      <td>3154.75</td>\n",
       "      <td>57.69</td>\n",
       "      <td>37.73</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151666</th>\n",
       "      <td>ZILK</td>\n",
       "      <td>150436</td>\n",
       "      <td>100</td>\n",
       "      <td>0.04</td>\n",
       "      <td>89753.41</td>\n",
       "      <td>90.00</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151667</th>\n",
       "      <td>ZINNANTI</td>\n",
       "      <td>150436</td>\n",
       "      <td>100</td>\n",
       "      <td>0.04</td>\n",
       "      <td>89753.45</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151668</th>\n",
       "      <td>ZITTERICH</td>\n",
       "      <td>150436</td>\n",
       "      <td>100</td>\n",
       "      <td>0.04</td>\n",
       "      <td>89753.48</td>\n",
       "      <td>98.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151669</th>\n",
       "      <td>ZULU</td>\n",
       "      <td>150436</td>\n",
       "      <td>100</td>\n",
       "      <td>0.04</td>\n",
       "      <td>89753.52</td>\n",
       "      <td>6.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151670</th>\n",
       "      <td>ZUSI</td>\n",
       "      <td>150436</td>\n",
       "      <td>100</td>\n",
       "      <td>0.04</td>\n",
       "      <td>89753.56</td>\n",
       "      <td>99.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151670 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name    rank    count  prop100k  cum_prop100k pctwhite pctblack  \\\n",
       "0           SMITH       1  2376206    880.85        880.85    73.35    22.22   \n",
       "1         JOHNSON       2  1857160    688.44       1569.30    61.55    33.80   \n",
       "2        WILLIAMS       3  1534042    568.66       2137.96    48.52    46.72   \n",
       "3           BROWN       4  1380145    511.62       2649.58    60.71    34.54   \n",
       "4           JONES       5  1362755    505.17       3154.75    57.69    37.73   \n",
       "...           ...     ...      ...       ...           ...      ...      ...   \n",
       "151666       ZILK  150436      100      0.04      89753.41    90.00     9.00   \n",
       "151667   ZINNANTI  150436      100      0.04      89753.45    98.00     0.00   \n",
       "151668  ZITTERICH  150436      100      0.04      89753.48    98.00        0   \n",
       "151669       ZULU  150436      100      0.04      89753.52     6.00    90.00   \n",
       "151670       ZUSI  150436      100      0.04      89753.56    99.00     0.00   \n",
       "\n",
       "       pctapi pctaian pct2prace pcthispanic  \n",
       "0        0.40    0.85      1.63        1.56  \n",
       "1        0.42    0.91      1.82        1.50  \n",
       "2        0.37    0.78      2.01        1.60  \n",
       "3        0.41    0.83      1.86        1.64  \n",
       "4        0.35    0.94      1.85        1.44  \n",
       "...       ...     ...       ...         ...  \n",
       "151666   0.00    0.00         0           0  \n",
       "151667   0.00    0.00         0           0  \n",
       "151668   0.00    0.00      0.00           0  \n",
       "151669   0.00    0.00         0           0  \n",
       "151670   0.00    0.00      0.00        0.00  \n",
       "\n",
       "[151670 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "NGRAMS = 2\n",
    "EPOCHS = 15\n",
    "YEAR = '2000'\n",
    "#YEAR = '2010'\n",
    "\n",
    "df = pd.read_csv('../data/census/census_%s.csv' % YEAR)\n",
    "df.dropna(subset=['name'], inplace=True)\n",
    "df.replace('(S)', 0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling with weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = df.sample(1000000, weights=df['count'], replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>prop100k</th>\n",
       "      <th>cum_prop100k</th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pctaian</th>\n",
       "      <th>pct2prace</th>\n",
       "      <th>pcthispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>LIN</td>\n",
       "      <td>624</td>\n",
       "      <td>49360</td>\n",
       "      <td>18.30</td>\n",
       "      <td>35075.39</td>\n",
       "      <td>2.29</td>\n",
       "      <td>0.13</td>\n",
       "      <td>95.13</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14531</th>\n",
       "      <td>DINGLER</td>\n",
       "      <td>14530</td>\n",
       "      <td>1881</td>\n",
       "      <td>0.70</td>\n",
       "      <td>72027.50</td>\n",
       "      <td>96.76</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>THORNTON</td>\n",
       "      <td>347</td>\n",
       "      <td>81191</td>\n",
       "      <td>30.10</td>\n",
       "      <td>28633.51</td>\n",
       "      <td>69.33</td>\n",
       "      <td>26.53</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>ELLIS</td>\n",
       "      <td>121</td>\n",
       "      <td>181934</td>\n",
       "      <td>67.44</td>\n",
       "      <td>18617.52</td>\n",
       "      <td>72.82</td>\n",
       "      <td>22.60</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>BUCKNER</td>\n",
       "      <td>1376</td>\n",
       "      <td>23645</td>\n",
       "      <td>8.77</td>\n",
       "      <td>44372.47</td>\n",
       "      <td>69.30</td>\n",
       "      <td>26.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TAYLOR</td>\n",
       "      <td>13</td>\n",
       "      <td>720370</td>\n",
       "      <td>267.04</td>\n",
       "      <td>5713.87</td>\n",
       "      <td>67.80</td>\n",
       "      <td>27.67</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>MARINO</td>\n",
       "      <td>1042</td>\n",
       "      <td>30735</td>\n",
       "      <td>11.39</td>\n",
       "      <td>41057.45</td>\n",
       "      <td>87.16</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.25</td>\n",
       "      <td>9.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33285</th>\n",
       "      <td>SPARANO</td>\n",
       "      <td>33248</td>\n",
       "      <td>648</td>\n",
       "      <td>0.24</td>\n",
       "      <td>79491.99</td>\n",
       "      <td>98.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WILLIAMS</td>\n",
       "      <td>3</td>\n",
       "      <td>1534042</td>\n",
       "      <td>568.66</td>\n",
       "      <td>2137.96</td>\n",
       "      <td>48.52</td>\n",
       "      <td>46.72</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>HIGGS</td>\n",
       "      <td>3275</td>\n",
       "      <td>10026</td>\n",
       "      <td>3.72</td>\n",
       "      <td>54988.90</td>\n",
       "      <td>72.24</td>\n",
       "      <td>23.98</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name   rank    count  prop100k  cum_prop100k pctwhite pctblack  \\\n",
       "623         LIN    624    49360     18.30      35075.39     2.29     0.13   \n",
       "14531   DINGLER  14530     1881      0.70      72027.50    96.76     0.37   \n",
       "346    THORNTON    347    81191     30.10      28633.51    69.33    26.53   \n",
       "120       ELLIS    121   181934     67.44      18617.52    72.82    22.60   \n",
       "1375    BUCKNER   1376    23645      8.77      44372.47    69.30    26.28   \n",
       "...         ...    ...      ...       ...           ...      ...      ...   \n",
       "12       TAYLOR     13   720370    267.04       5713.87    67.80    27.67   \n",
       "1041     MARINO   1042    30735     11.39      41057.45    87.16     0.63   \n",
       "33285   SPARANO  33248      648      0.24      79491.99    98.30        0   \n",
       "2      WILLIAMS      3  1534042    568.66       2137.96    48.52    46.72   \n",
       "3274      HIGGS   3275    10026      3.72      54988.90    72.24    23.98   \n",
       "\n",
       "      pctapi pctaian pct2prace pcthispanic  \n",
       "623    95.13    0.03      2.02        0.40  \n",
       "14531      0       0      0.85        1.59  \n",
       "346     0.37    0.66      1.80        1.31  \n",
       "120     0.44    0.66      1.64        1.83  \n",
       "1375    0.28    0.83      1.89        1.41  \n",
       "...      ...     ...       ...         ...  \n",
       "12      0.39    0.75      1.78        1.61  \n",
       "1041    0.90    0.20      1.25        9.86  \n",
       "33285      0    0.00      0.00        1.54  \n",
       "2       0.37    0.78      2.01        1.60  \n",
       "3274    0.41    0.34      1.60        1.44  \n",
       "\n",
       "[1000000 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign race by pertcentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "\n",
    "races = ['white', 'black', 'api', 'hispanic']\n",
    "\n",
    "def to_race(c):\n",
    "    w = np.array(c).astype(float)\n",
    "    if w.sum() == 0:\n",
    "        return 'white'\n",
    "    probs = w/w.sum()    \n",
    "    return choice(races, p=probs)\n",
    "\n",
    "sdf['race'] = sdf[['pctwhite', 'pctblack', 'pctapi', 'pcthispanic']].apply(lambda c: to_race(c), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the correctness of race assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>rank</th>\n",
       "      <th>count</th>\n",
       "      <th>prop100k</th>\n",
       "      <th>cum_prop100k</th>\n",
       "      <th>pctwhite</th>\n",
       "      <th>pctblack</th>\n",
       "      <th>pctapi</th>\n",
       "      <th>pctaian</th>\n",
       "      <th>pct2prace</th>\n",
       "      <th>pcthispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMITH</td>\n",
       "      <td>1</td>\n",
       "      <td>2376206</td>\n",
       "      <td>880.85</td>\n",
       "      <td>880.85</td>\n",
       "      <td>73.35</td>\n",
       "      <td>22.22</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name  rank    count  prop100k  cum_prop100k pctwhite pctblack pctapi  \\\n",
       "0  SMITH     1  2376206    880.85        880.85    73.35    22.22   0.40   \n",
       "\n",
       "  pctaian pct2prace pcthispanic  \n",
       "0    0.85      1.63        1.56  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.name == 'SMITH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>api</th>\n",
       "      <td>0.437525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>22.608873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hispanic</th>\n",
       "      <td>1.739927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>75.213675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name\n",
       "race               \n",
       "api        0.437525\n",
       "black     22.608873\n",
       "hispanic   1.739927\n",
       "white     75.213675"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf = sdf[sdf.name=='SMITH'].groupby(['race']).agg({'name': 'count'})\n",
    "xdf * 100 / xdf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>api</th>\n",
       "      <td>35590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>125705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hispanic</th>\n",
       "      <td>127898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>white</th>\n",
       "      <td>710807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name_last\n",
       "race               \n",
       "api           35590\n",
       "black        125705\n",
       "hispanic     127898\n",
       "white        710807"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Additional features\n",
    "sdf['name_last'] = sdf.name.str.title()\n",
    "sdf.groupby('race').agg({'name_last': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only last name in Census data\n",
    "sdf['name_last_name_first'] = sdf['name_last']\n",
    "\n",
    "# build n-gram list\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "#vect = CountVectorizer(analyzer='char', ngram_range=(2, 2), lowercase=False) \n",
    "a = vect.fit_transform(sdf.name_last_name_first)\n",
    "vocab = vect.vocabulary_\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_vocab = sorted(vocab.items(), key=operator.itemgetter(1))\n",
    "cols = list(map(operator.itemgetter(0), sorted_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Aa</th>\n",
       "      <th>Ab</th>\n",
       "      <th>Ac</th>\n",
       "      <th>Ad</th>\n",
       "      <th>Ae</th>\n",
       "      <th>Af</th>\n",
       "      <th>Ag</th>\n",
       "      <th>Ah</th>\n",
       "      <th>Ai</th>\n",
       "      <th>Aj</th>\n",
       "      <th>...</th>\n",
       "      <th>zp</th>\n",
       "      <th>zq</th>\n",
       "      <th>zr</th>\n",
       "      <th>zs</th>\n",
       "      <th>zt</th>\n",
       "      <th>zu</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zy</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows Ã— 955 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Aa  Ab  Ac  Ad  Ae  Af  Ag  Ah  Ai  Aj  ...  zp  zq  zr  zs  zt  zu  \\\n",
       "0        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "1        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "2        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "3        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "4        0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "...     ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..   \n",
       "999995   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "999996   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "999997   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "999998   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "999999   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   \n",
       "\n",
       "        zv  zw  zy  zz  \n",
       "0        0   0   0   0  \n",
       "1        0   0   0   0  \n",
       "2        0   0   0   0  \n",
       "3        0   0   0   0  \n",
       "4        0   0   0   0  \n",
       "...     ..  ..  ..  ..  \n",
       "999995   0   0   0   0  \n",
       "999996   0   0   0   0  \n",
       "999997   0   0   0   0  \n",
       "999998   0   0   0   0  \n",
       "999999   0   0   0   0  \n",
       "\n",
       "[1000000 rows x 955 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = pd.DataFrame(a.todense(), columns=cols)\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       955.000000\n",
       "mean       5556.781152\n",
       "std       12700.866095\n",
       "min           3.000000\n",
       "25%          89.500000\n",
       "50%         946.000000\n",
       "75%        5495.500000\n",
       "max      175538.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df.sum().sort_values(ascending=False).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "er    175538\n",
       "on    123764\n",
       "an    106961\n",
       "ar    100367\n",
       "ll     86325\n",
       "       ...  \n",
       "jh         3\n",
       "Xe         3\n",
       "Zv         3\n",
       "Cn         3\n",
       "qv         3\n",
       "Length: 955, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 20)\n",
    "count_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 956\n",
      "Max feature len = 14, Avg. feature len = 5\n"
     ]
    }
   ],
   "source": [
    "# sort n-gram by freq (highest -> lowest)\n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    #print(b, c, a[:, c].sum())\n",
    "    words.append((a[:, c].sum(), b))\n",
    "    #break\n",
    "words = sorted(words, reverse=True)\n",
    "words_list = ['UNK']\n",
    "words_list.extend([w[1] for w in words])\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)\n",
    "\n",
    "\n",
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi\n",
    "\n",
    "# build X from index of n-gram sequence\n",
    "X = np.array(sdf.name_last_name_first.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "\n",
    "# check max/avg feature\n",
    "X_len = []\n",
    "for x in X:\n",
    "    X_len.append(len(x))\n",
    "\n",
    "max_feature_len = max(X_len)\n",
    "avg_feature_len = int(np.mean(X_len))\n",
    "\n",
    "print(\"Max feature len = %d, Avg. feature len = %d\" % (max_feature_len, avg_feature_len))\n",
    "y = np.array(sdf.race.astype('category').cat.codes)\n",
    "\n",
    "# Split train and test dataset\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "955"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a LSTM model\n",
    "\n",
    "ref: http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000 train sequences\n",
      "200000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (800000, 20)\n",
      "X_test shape: (200000, 20)\n",
      "4 classes\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (800000, 4)\n",
      "y_test shape: (200000, 4)\n"
     ]
    }
   ],
   "source": [
    "'''The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "Notes:\n",
    "\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model\n",
    "\n",
    "max_features = num_words # 20000\n",
    "feature_len = 20 # avg_feature_len # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=feature_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=feature_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 20, 32)            30592     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               82432     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 113,540\n",
      "Trainable params: 113,540\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 14:50:35.627956: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-20 14:50:35.628132: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-20 14:50:35.628152: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-server-2): /proc/driver/nvidia/version does not exist\n",
      "2021-12-20 14:50:35.628417: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=feature_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-20 14:50:36.001889: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-12-20 14:50:36.002391: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2250000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 [==============================] - 452s 19ms/step - loss: 0.5997 - accuracy: 0.7959 - val_loss: 0.5380 - val_accuracy: 0.8135\n",
      "Epoch 2/15\n",
      "22500/22500 [==============================] - 426s 19ms/step - loss: 0.5327 - accuracy: 0.8165 - val_loss: 0.5176 - val_accuracy: 0.8199\n",
      "Epoch 3/15\n",
      "22500/22500 [==============================] - 424s 19ms/step - loss: 0.5143 - accuracy: 0.8218 - val_loss: 0.5077 - val_accuracy: 0.8224\n",
      "Epoch 4/15\n",
      "22500/22500 [==============================] - 424s 19ms/step - loss: 0.5070 - accuracy: 0.8234 - val_loss: 0.5037 - val_accuracy: 0.8238\n",
      "Epoch 5/15\n",
      "22500/22500 [==============================] - 424s 19ms/step - loss: 0.4992 - accuracy: 0.8256 - val_loss: 0.4993 - val_accuracy: 0.8247\n",
      "Epoch 6/15\n",
      "22500/22500 [==============================] - 425s 19ms/step - loss: 0.4963 - accuracy: 0.8266 - val_loss: 0.4966 - val_accuracy: 0.8256\n",
      "Epoch 7/15\n",
      "22500/22500 [==============================] - 423s 19ms/step - loss: 0.4982 - accuracy: 0.8255 - val_loss: 0.4952 - val_accuracy: 0.8263\n",
      "Epoch 8/15\n",
      "22500/22500 [==============================] - 424s 19ms/step - loss: 0.4939 - accuracy: 0.8270 - val_loss: 0.4959 - val_accuracy: 0.8259\n",
      "Epoch 9/15\n",
      "22500/22500 [==============================] - 425s 19ms/step - loss: 0.4945 - accuracy: 0.8261 - val_loss: 0.4925 - val_accuracy: 0.8264\n",
      "Epoch 10/15\n",
      "22500/22500 [==============================] - 423s 19ms/step - loss: 0.4893 - accuracy: 0.8273 - val_loss: 0.4916 - val_accuracy: 0.8265\n",
      "Epoch 11/15\n",
      "22500/22500 [==============================] - 422s 19ms/step - loss: 0.4907 - accuracy: 0.8281 - val_loss: 0.4912 - val_accuracy: 0.8270\n",
      "Epoch 12/15\n",
      "22500/22500 [==============================] - 423s 19ms/step - loss: 0.4886 - accuracy: 0.8280 - val_loss: 0.4912 - val_accuracy: 0.8269\n",
      "Epoch 13/15\n",
      "22500/22500 [==============================] - 422s 19ms/step - loss: 0.4896 - accuracy: 0.8280 - val_loss: 0.4895 - val_accuracy: 0.8275\n",
      "Epoch 14/15\n",
      "22500/22500 [==============================] - 419s 19ms/step - loss: 0.4898 - accuracy: 0.8278 - val_loss: 0.4903 - val_accuracy: 0.8272\n",
      "Epoch 15/15\n",
      "22500/22500 [==============================] - 420s 19ms/step - loss: 0.4892 - accuracy: 0.8275 - val_loss: 0.4902 - val_accuracy: 0.8275\n",
      "6250/6250 [==============================] - 28s 5ms/step - loss: 0.4893 - accuracy: 0.8286\n",
      "Test score: 0.4892885088920593\n",
      "Test accuracy: 0.8285549879074097\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=EPOCHS,\n",
    "          validation_split=0.1, verbose=1)\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 - 27s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         api       0.88      0.64      0.74      7118\n",
      "       black       0.60      0.05      0.09     25141\n",
      "    hispanic       0.86      0.84      0.85     25580\n",
      "       white       0.82      0.97      0.89    142161\n",
      "\n",
      "    accuracy                           0.83    200000\n",
      "   macro avg       0.79      0.63      0.65    200000\n",
      "weighted avg       0.80      0.83      0.78    200000\n",
      "\n",
      "[[  4572     17    612   1917]\n",
      " [    92   1287    178  23584]\n",
      " [   103     40  21561   3876]\n",
      " [   404    809   2657 138291]]\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_test, verbose=2) # to predict probability\n",
    "y_pred = np.argmax(p, axis=-1)\n",
    "target_names = list(sdf.race.astype('category').cat.categories)\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./census/lstm/census%s_ln_lstm.h5' % YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(words_list, columns=['vocab'])\n",
    "words_df.to_csv('./census/lstm/census%s_ln_vocab.csv' % YEAR, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdf.to_csv('./census/lstm/census%s_race.csv' % YEAR, columns=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
