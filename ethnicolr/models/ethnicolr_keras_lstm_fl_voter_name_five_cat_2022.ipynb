{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/jupyter/lib/python3.9/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "2.8.3\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>name_first</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hessler-Smith</td>\n",
       "      <td>Jason</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rogers</td>\n",
       "      <td>Renee</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bartolome</td>\n",
       "      <td>Crystal</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bailey</td>\n",
       "      <td>Donna</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carlson</td>\n",
       "      <td>Greggory</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15455105</th>\n",
       "      <td>Ballew</td>\n",
       "      <td>Christina</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15455106</th>\n",
       "      <td>Watts</td>\n",
       "      <td>Mark</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15455107</th>\n",
       "      <td>McRae</td>\n",
       "      <td>Evelyn</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15455108</th>\n",
       "      <td>Ward</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15455109</th>\n",
       "      <td>Edenfield</td>\n",
       "      <td>Marcus</td>\n",
       "      <td>nh_white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15454979 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              name_last name_first      race\n",
       "0         Hessler-Smith      Jason  nh_white\n",
       "1                Rogers      Renee  nh_white\n",
       "2             Bartolome    Crystal  nh_white\n",
       "3                Bailey      Donna  nh_white\n",
       "4               Carlson   Greggory  nh_white\n",
       "...                 ...        ...       ...\n",
       "15455105         Ballew  Christina  nh_white\n",
       "15455106          Watts       Mark  nh_white\n",
       "15455107          McRae     Evelyn  nh_white\n",
       "15455108           Ward  Stephanie  nh_white\n",
       "15455109      Edenfield     Marcus  nh_white\n",
       "\n",
       "[15454979 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "NGRAMS = 2\n",
    "SAMPLE = 1000000\n",
    "EPOCHS = 20\n",
    "\n",
    "# Florida voter\n",
    "df = pd.read_csv('/opt/data/fl_voterreg/fl_reg_name_race_2022.csv.gz')\n",
    "df.dropna(subset=['name_first', 'name_last'], inplace=True)\n",
    "df['race'] = df.race.map({'native_indian': 'other', 'asian': 'asian', 'nh_black': 'nh_black', 'hispanic': 'hispanic', 'nh_white': 'nh_white', 'other': 'other', 'multi_racial': 'other', 'unknown': 'unknown'})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "      <th>name_first</th>\n",
       "      <th>race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4180262</th>\n",
       "      <td>Bhikhari</td>\n",
       "      <td>Chandika</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050170</th>\n",
       "      <td>Harilal</td>\n",
       "      <td>Sreekumar</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241801</th>\n",
       "      <td>Huynh</td>\n",
       "      <td>Lana</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312038</th>\n",
       "      <td>Patel</td>\n",
       "      <td>Vaidehi</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13782727</th>\n",
       "      <td>Wang</td>\n",
       "      <td>Lingli</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11185683</th>\n",
       "      <td>Hinostroza</td>\n",
       "      <td>Jon</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7373319</th>\n",
       "      <td>Holguin</td>\n",
       "      <td>Matthew</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10664871</th>\n",
       "      <td>Butler</td>\n",
       "      <td>Russell</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5528330</th>\n",
       "      <td>Jones</td>\n",
       "      <td>Daisha</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6786661</th>\n",
       "      <td>Garth</td>\n",
       "      <td>Carmen</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name_last name_first   race\n",
       "4180262     Bhikhari   Chandika  asian\n",
       "2050170      Harilal  Sreekumar  asian\n",
       "241801         Huynh       Lana  asian\n",
       "5312038        Patel    Vaidehi  asian\n",
       "13782727        Wang     Lingli  asian\n",
       "...              ...        ...    ...\n",
       "11185683  Hinostroza        Jon  other\n",
       "7373319      Holguin    Matthew  other\n",
       "10664871      Butler    Russell  other\n",
       "5528330        Jones     Daisha  other\n",
       "6786661        Garth     Carmen  other\n",
       "\n",
       "[1000000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf = df[df.race.isin(['unknown']) == False].groupby(['race']).sample(int(SAMPLE/5), random_state=21)\n",
    "del df\n",
    "\n",
    "# Additional features\n",
    "sdf['name_first'] = sdf.name_first.str.title()\n",
    "sdf['name_last'] = sdf.name_last.str.title()\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asian</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hispanic</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nh_black</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nh_white</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name_last\n",
       "race               \n",
       "asian        200000\n",
       "hispanic     200000\n",
       "nh_black     200000\n",
       "nh_white     200000\n",
       "other        200000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdf = sdf.groupby('race').agg({'name_last': 'count'})\n",
    "rdf.to_csv('./fl_voter_reg/lstm/fl_name_five_cat_race_2022.csv', columns=[])\n",
    "rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_last</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asian</th>\n",
       "      <td>50546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hispanic</th>\n",
       "      <td>55285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nh_black</th>\n",
       "      <td>29799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nh_white</th>\n",
       "      <td>65731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>68123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name_last\n",
       "race               \n",
       "asian         50546\n",
       "hispanic      55285\n",
       "nh_black      29799\n",
       "nh_white      65731\n",
       "other         68123"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf.groupby('race').agg({'name_last': 'nunique'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words = 1329\n",
      "Max feature len = 46, Avg. feature len = 12\n"
     ]
    }
   ],
   "source": [
    "# concat last name and first name\n",
    "sdf['name_last_name_first'] = sdf['name_last'] + ' ' + sdf['name_first']\n",
    "\n",
    "# build n-gram list\n",
    "vect = CountVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False) \n",
    "a = vect.fit_transform(sdf.name_last_name_first)\n",
    "vocab = vect.vocabulary_\n",
    "\n",
    "# sort n-gram by freq (highest -> lowest)\n",
    "words = []\n",
    "for b in vocab:\n",
    "    c = vocab[b]\n",
    "    #print(b, c, a[:, c].sum())\n",
    "    words.append((a[:, c].sum(), b))\n",
    "    #break\n",
    "words = sorted(words, reverse=True)\n",
    "words_list = [w[1] for w in words]\n",
    "num_words = len(words_list)\n",
    "print(\"num_words = %d\" % num_words)\n",
    "\n",
    "\n",
    "def find_ngrams(text, n):\n",
    "    a = zip(*[text[i:] for i in range(n)])\n",
    "    wi = []\n",
    "    for i in a:\n",
    "        w = ''.join(i)\n",
    "        try:\n",
    "            idx = words_list.index(w)\n",
    "        except:\n",
    "            idx = 0\n",
    "        wi.append(idx)\n",
    "    return wi\n",
    "\n",
    "# build X from index of n-gram sequence\n",
    "X = np.array(sdf.name_last_name_first.apply(lambda c: find_ngrams(c, NGRAMS)))\n",
    "\n",
    "# check max/avg feature\n",
    "X_len = []\n",
    "for x in X:\n",
    "    X_len.append(len(x))\n",
    "\n",
    "max_feature_len = max(X_len)\n",
    "avg_feature_len = int(np.mean(X_len))\n",
    "\n",
    "print(\"Max feature len = %d, Avg. feature len = %d\" % (max_feature_len, avg_feature_len))\n",
    "y = np.array(sdf.race.astype('category').cat.codes)\n",
    "\n",
    "# Split train and test dataset\n",
    "X_train,  X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a LSTM model\n",
    "\n",
    "ref: http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800000 train sequences\n",
      "200000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (800000, 20)\n",
      "X_test shape: (200000, 20)\n",
      "5 classes\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (800000, 5)\n",
      "y_test shape: (200000, 5)\n"
     ]
    }
   ],
   "source": [
    "'''The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "Notes:\n",
    "\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import load_model\n",
    "\n",
    "max_features = num_words # 20000\n",
    "feature_len = 20 # avg_feature_len # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=feature_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=feature_len)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, 'classes')\n",
    "\n",
    "print('Convert class vector to binary class matrix '\n",
    "      '(for use with categorical_crossentropy)')\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 20, 32)            42528     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               82432     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 645       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125,605\n",
      "Trainable params: 125,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=feature_len))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/20\n",
      "22500/22500 [==============================] - 1130s 50ms/step - loss: 1.1266 - accuracy: 0.5452 - val_loss: 1.0652 - val_accuracy: 0.5737\n",
      "Epoch 2/20\n",
      "22500/22500 [==============================] - 973s 43ms/step - loss: 1.0558 - accuracy: 0.5795 - val_loss: 1.0306 - val_accuracy: 0.5908\n",
      "Epoch 3/20\n",
      "22500/22500 [==============================] - 922s 41ms/step - loss: 1.0298 - accuracy: 0.5923 - val_loss: 1.0122 - val_accuracy: 0.5985\n",
      "Epoch 4/20\n",
      "22500/22500 [==============================] - 849s 38ms/step - loss: 1.0153 - accuracy: 0.5984 - val_loss: 1.0009 - val_accuracy: 0.6029\n",
      "Epoch 5/20\n",
      "22500/22500 [==============================] - 810s 36ms/step - loss: 1.0060 - accuracy: 0.6032 - val_loss: 0.9955 - val_accuracy: 0.6072\n",
      "Epoch 6/20\n",
      "22500/22500 [==============================] - 894s 40ms/step - loss: 1.0000 - accuracy: 0.6061 - val_loss: 0.9905 - val_accuracy: 0.6100\n",
      "Epoch 7/20\n",
      "22500/22500 [==============================] - 923s 41ms/step - loss: 0.9959 - accuracy: 0.6075 - val_loss: 0.9897 - val_accuracy: 0.6109\n",
      "Epoch 8/20\n",
      "22500/22500 [==============================] - 955s 42ms/step - loss: 0.9925 - accuracy: 0.6091 - val_loss: 0.9842 - val_accuracy: 0.6128\n",
      "Epoch 9/20\n",
      "22500/22500 [==============================] - 927s 41ms/step - loss: 0.9900 - accuracy: 0.6106 - val_loss: 0.9867 - val_accuracy: 0.6144\n",
      "Epoch 10/20\n",
      "22500/22500 [==============================] - 918s 41ms/step - loss: 0.9880 - accuracy: 0.6118 - val_loss: 0.9792 - val_accuracy: 0.6151\n",
      "Epoch 11/20\n",
      "22500/22500 [==============================] - 909s 40ms/step - loss: 0.9863 - accuracy: 0.6118 - val_loss: 0.9818 - val_accuracy: 0.6153\n",
      "Epoch 12/20\n",
      "22500/22500 [==============================] - 965s 43ms/step - loss: 0.9845 - accuracy: 0.6133 - val_loss: 0.9776 - val_accuracy: 0.6163\n",
      "Epoch 13/20\n",
      "22500/22500 [==============================] - 917s 41ms/step - loss: 0.9831 - accuracy: 0.6135 - val_loss: 0.9795 - val_accuracy: 0.6152\n",
      "Epoch 14/20\n",
      "22500/22500 [==============================] - 902s 40ms/step - loss: 0.9824 - accuracy: 0.6135 - val_loss: 0.9762 - val_accuracy: 0.6173\n",
      "Epoch 15/20\n",
      "22500/22500 [==============================] - 902s 40ms/step - loss: 0.9812 - accuracy: 0.6147 - val_loss: 0.9798 - val_accuracy: 0.6169\n",
      "Epoch 16/20\n",
      "22500/22500 [==============================] - 928s 41ms/step - loss: 0.9802 - accuracy: 0.6145 - val_loss: 0.9745 - val_accuracy: 0.6188\n",
      "Epoch 17/20\n",
      "22500/22500 [==============================] - 916s 41ms/step - loss: 0.9791 - accuracy: 0.6149 - val_loss: 0.9772 - val_accuracy: 0.6177\n",
      "Epoch 18/20\n",
      "22500/22500 [==============================] - 976s 43ms/step - loss: 0.9786 - accuracy: 0.6155 - val_loss: 0.9765 - val_accuracy: 0.6182\n",
      "Epoch 19/20\n",
      "22500/22500 [==============================] - 969s 43ms/step - loss: 0.9776 - accuracy: 0.6160 - val_loss: 0.9722 - val_accuracy: 0.6191\n",
      "Epoch 20/20\n",
      "22500/22500 [==============================] - 850s 38ms/step - loss: 0.9769 - accuracy: 0.6164 - val_loss: 0.9725 - val_accuracy: 0.6184\n",
      "6250/6250 [==============================] - 45s 7ms/step - loss: 0.9723 - accuracy: 0.6198\n",
      "Test score: 0.9723479151725769\n",
      "Test accuracy: 0.6197550296783447\n"
     ]
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=EPOCHS,\n",
    "          validation_split=0.1, verbose=1)\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size, verbose=1)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9723479151725769\n",
      "Test accuracy: 0.6197550296783447\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 - 38s - 38s/epoch - 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       asian       0.75      0.67      0.71     40000\n",
      "    hispanic       0.73      0.86      0.79     40000\n",
      "    nh_black       0.59      0.73      0.65     40000\n",
      "    nh_white       0.50      0.72      0.59     40000\n",
      "       other       0.45      0.11      0.17     40000\n",
      "\n",
      "    accuracy                           0.62    200000\n",
      "   macro avg       0.60      0.62      0.58    200000\n",
      "weighted avg       0.60      0.62      0.58    200000\n",
      "\n",
      "[[26981  3447  2661  4641  2270]\n",
      " [  982 34593  1348  2392   685]\n",
      " [  795   870 29170  8293   872]\n",
      " [ 1025  2192  6538 28963  1282]\n",
      " [ 6343  6051  9938 13424  4244]]\n"
     ]
    }
   ],
   "source": [
    "p = model.predict(X_test, verbose=2) # to predict probability\n",
    "y_pred = np.argmax(p, axis=-1)\n",
    "target_names = list(sdf.race.astype('category').cat.categories)\n",
    "print(classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names))\n",
    "print(confusion_matrix(np.argmax(y_test, axis=1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./fl_voter_reg/lstm/fl_all_fullname_lstm_5_cat_2022.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(words_list, columns=['vocab'])\n",
    "words_df.to_csv('./fl_voter_reg/lstm/fl_all_fullname_vocab_5_cat_2022.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
